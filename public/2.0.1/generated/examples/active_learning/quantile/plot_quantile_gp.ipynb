{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GP regressor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nfrom gemseo import configure\nfrom gemseo import configure_logger\nfrom gemseo import sample_disciplines\nfrom gemseo.mlearning.regression.algos.gpr import GaussianProcessRegressor\nfrom gemseo.mlearning.regression.algos.ot_gpr import OTGaussianProcessRegressor\nfrom gemseo.uncertainty.statistics.empirical_statistics import EmpiricalStatistics\nfrom numpy import concatenate\nfrom numpy import unique\n\nfrom gemseo_mlearning.active_learning.active_learning_algo import ActiveLearningAlgo\nfrom gemseo_mlearning.problems.rosenbrock.rosenbrock_discipline import (\n    RosenbrockDiscipline,\n)\nfrom gemseo_mlearning.problems.rosenbrock.rosenbrock_space import RosenbrockSpace\n\n# Update the configuration of |g| to speed up the script (use configure() with care)\nconfigure(False, False, True, False, False, False, False)\n\nconfigure_logger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The use of active learning methods\ndedicated to quantile estimation\nis illustrated in this example.\nMore specifically,\nwe aim to test here\nthe impact of the choice\nto test the impact of the choice\nof the GP on the active learning procedure,\nThe function with the quantile of interest is\nthe Rosenbrock function $f(x_1,x_2)=(1-x_1)^2+100(x_2-x_1^2)^2$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = RosenbrockDiscipline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "with $x_1$ and $x_2$ uniformly distributed over $[-2,2]^2$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uncertain_space = RosenbrockSpace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First,\nwe create an initial training dataset using an optimal LHS including 10 samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "learning_dataset = sample_disciplines(\n    [discipline], uncertain_space, \"y\", algo_name=\"OT_OPT_LHS\", n_samples=10\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and one Gaussian process regressor OpenTURNS:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regressor_1 = OTGaussianProcessRegressor(\n    learning_dataset,\n    trend=\"quadratic\",\n)\n# and the other from scikit-learn:\nregressor_2 = GaussianProcessRegressor(learning_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe build two active learning algorithms\nto test the impact of the choice\nof the GP on the active learning procedure,\none from the OpenTURNS library\nand the second from scikit-learn.\nThose two are notably different,\nin particular,\nGPs from scikit-learn\ndo not include trend modeling.\nAll other settings are put to\ntheir default value.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "level = 0.35\nactive_learning_1 = ActiveLearningAlgo(\n    \"Quantile\",\n    uncertain_space,\n    regressor_1,\n    level=level,\n    uncertain_space=uncertain_space,\n)\nactive_learning_2 = ActiveLearningAlgo(\n    \"Quantile\",\n    uncertain_space,\n    regressor_2,\n    level=level,\n    uncertain_space=uncertain_space,\n)\nactive_learning_1.acquire_new_points(discipline, 20)\nactive_learning_2.acquire_new_points(discipline, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To study the results,\nwe extract first\nthe data associated\nto the history\nof the quantity of interest\nfor both active learning procedures\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "history_1 = active_learning_1.qoi_history\nhistory_2 = active_learning_2.qoi_history\n# and we compare them in a plot\nplt.plot(history_1[0], concatenate(history_1[1]), marker=\"o\", label=\"OpenTURNS GP\")\nplt.plot(history_2[0], concatenate(history_2[1]), marker=\"o\", label=\"Scikit-learn GP\")\nplt.xlabel(\"Number of evaluations\")\nplt.ylabel(\"Quantile\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also\ncompare the estimated quantile\nfrom the active learning procedure\nto the Monte Carlo estimate\nfor both algorithms\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = sample_disciplines(\n    [discipline], uncertain_space, \"y\", algo_name=\"OT_MONTE_CARLO\", n_samples=1000\n)\nreference_quantile = EmpiricalStatistics(dataset, [\"y\"]).compute_quantile(level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally,\nfor both active learning algorithms,\nwe plot the training points,\nalongside the original model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Creation of the grid\n# and estimation of the different quantities\nn_test = 10\nobservations = sample_disciplines(\n    [discipline], uncertain_space, \"y\", algo_name=\"OT_FULLFACT\", n_samples=n_test**2\n).values\n\n# Plotting the contours of the Rosenbrock function\n# alongside the learning points\nplt.figure()\npoints_1 = active_learning_1.regressor.learning_set.to_numpy()\npoints_2 = active_learning_2.regressor.learning_set.to_numpy()\nlevel_set = plt.contour(\n    unique(observations[:, 0]),\n    unique(observations[:, 1]),\n    observations[:, 2].reshape(n_test, n_test),\n    levels=[reference_quantile[\"y\"]],\n    colors=\"red\",\n)\nplt.clabel(level_set, levels=[reference_quantile[\"y\"]], fontsize=10, colors=\"red\")\nplt.annotate(\"True level set\", (-0.2, 0.75), color=\"red\")\nplt.contour(\n    unique(observations[:, 0]),\n    unique(observations[:, 1]),\n    observations[:, 2].reshape(n_test, n_test),\n)\nbar = plt.colorbar()\nbar.set_label(r\"$f(x_1,x_2)$\")\nplt.scatter(points_1[:, 0], points_1[:, 1], marker=\"*\", label=\"OpenTURNS GP\")\nplt.scatter(points_2[:, 0], points_2[:, 1], marker=\"*\", label=\"scikit-learn GP\")\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
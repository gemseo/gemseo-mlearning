{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Acquisition algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nfrom gemseo import configure\nfrom gemseo import configure_logger\nfrom gemseo import sample_disciplines\nfrom gemseo.disciplines.surrogate import SurrogateDiscipline\nfrom gemseo.mlearning.regression.algos.ot_gpr import OTGaussianProcessRegressor\nfrom numpy import unique\n\nfrom gemseo_mlearning.active_learning.active_learning_algo import ActiveLearningAlgo\nfrom gemseo_mlearning.problems.rosenbrock.rosenbrock_discipline import (\n    RosenbrockDiscipline,\n)\nfrom gemseo_mlearning.problems.rosenbrock.rosenbrock_space import RosenbrockSpace\n\n# Update the configuration of |g| to speed up the script (use configure() with care)\nconfigure(False, False, True, False, False, False, False)\n\nconfigure_logger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The use of active learning methods\ndedicated to optimization\nis illustrated in this example.\nMore specifically,\nwe aim to test here\nthe impact of the choice\nof the optimization algorithm\nused to find the next\nacquisition point\non the active learning procedure.\nThe function with the level set of interest is\nthe Rosenbrock function $f(x_1,x_2)=(1-x_1)^2+100(x_2-x_1^2)^2$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = RosenbrockDiscipline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "with $x_1$ and $x_2$ belonging to $[-2,2]^2$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_space = RosenbrockSpace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First,\nwe create an initial training dataset using an optimal LHS including 10 samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "learning_dataset = sample_disciplines(\n    [discipline], input_space, \"y\", algo_name=\"OT_OPT_LHS\", n_samples=10\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and two identical initial\nGaussian process regressors from OpenTURNS:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regressor_1 = OTGaussianProcessRegressor(\n    learning_dataset,\n    trend=\"quadratic\",\n)\nregressor_2 = OTGaussianProcessRegressor(\n    learning_dataset,\n    trend=\"quadratic\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe build two active learning algorithms\nto test the impact of the choice\nof acquisition algorithm\nused to optimize the acquisition criterion\non the active learning procedure.\nOne uses the SLSQP gradient-based routine\nin a multistart fashion (default)\nfor the optimization\nof the acquisition criterion,\nand the second the NELDER-MEAD gradient-free algorithm,\nalso in a multistart fashion.\nAll other settings are put to\ntheir default values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "value_level = 400\nactive_learning_1 = ActiveLearningAlgo(\n    \"LevelSet\",\n    input_space,\n    regressor_1,\n    output_value=value_level,\n)\nactive_learning_2 = ActiveLearningAlgo(\n    \"LevelSet\",\n    input_space,\n    regressor_2,\n    output_value=value_level,\n)\nactive_learning_1.acquire_new_points(discipline, n_samples=20)\nactive_learning_2.set_acquisition_algorithm(algo_name=\"NELDER-MEAD\")\nactive_learning_2.acquire_new_points(discipline, n_samples=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To study the results,\nfor both active learning algorithms,\nwe plot the training points,\nthe estimated level sets\nalongside the original model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Creation of the grid\n# and estimation of the different quantities\nn_test = 10\nsurrogate_1 = SurrogateDiscipline(active_learning_1.regressor)\nsurrogate_2 = SurrogateDiscipline(active_learning_2.regressor)\nobservations = sample_disciplines(\n    [discipline], input_space, \"y\", algo_name=\"OT_FULLFACT\", n_samples=n_test**2\n).values\nobservations_gp_1 = sample_disciplines(\n    [surrogate_1], input_space, \"y\", algo_name=\"OT_FULLFACT\", n_samples=n_test**2\n).values\nobservations_gp_2 = sample_disciplines(\n    [surrogate_2], input_space, \"y\", algo_name=\"OT_FULLFACT\", n_samples=n_test**2\n).values\n\n# Plotting the contours of the Rosenbrock function\n# alongside the learning points\n# and the level sets.\nplt.figure()\npoints_1 = active_learning_1.regressor.learning_set.to_numpy()\npoints_2 = active_learning_2.regressor.learning_set.to_numpy()\nlevel_set_exact = plt.contour(\n    unique(observations[:, 0]),\n    unique(observations[:, 1]),\n    observations[:, 2].reshape(n_test, n_test),\n    levels=[value_level],\n    colors=\"red\",\n)\nlevel_set_gp_1 = plt.contour(\n    unique(observations_gp_1[:, 0]),\n    unique(observations_gp_1[:, 1]),\n    observations_gp_1[:, 2].reshape(n_test, n_test),\n    levels=[value_level],\n    colors=\"tab:blue\",\n    linestyles=\"dotted\",\n)\nlevel_set_gp_2 = plt.contour(\n    unique(observations_gp_2[:, 0]),\n    unique(observations_gp_2[:, 1]),\n    observations_gp_2[:, 2].reshape(n_test, n_test),\n    levels=[value_level],\n    colors=\"tab:orange\",\n    linestyles=\"dotted\",\n)\nplt.clabel(level_set_exact, levels=[value_level], fontsize=10, colors=\"red\")\nplt.annotate(\"Target level set\", (-0.2, 0.75), color=\"red\")\nplt.annotate(\n    \"Level set estimated with the multistart SLSQP\", (-1.5, 0.5), color=\"tab:blue\"\n)\nplt.annotate(\n    \"Level set estimated with the multistart NELDER-MEAD\",\n    (-1.5, 0.25),\n    color=\"tab:orange\",\n)\nplt.contour(\n    unique(observations[:, 0]),\n    unique(observations[:, 1]),\n    observations[:, 2].reshape(n_test, n_test),\n)\nbar = plt.colorbar()\nbar.set_label(r\"$f(x_1,x_2)$\")\nplt.scatter(\n    points_1[:, 0],\n    points_1[:, 1],\n    marker=\"*\",\n    label=\"Learning points from algo with multistart SLSQP\",\n)\nplt.scatter(\n    points_2[:, 0],\n    points_2[:, 1],\n    marker=\"*\",\n    label=\"Learning points from algo with NELDER-MEAD\",\n)\nplt.xlabel(r\"$x_1$\")\nplt.ylabel(r\"$x_2$\")\nplt.legend()\nplt.show()\n# The estimated level set\n# estimated with both acquisition algorithm\n# provide a good approximation of the target.\n# Furthermore,\n# though the learning points are not strictly\n# speaking the same,\n# several are located close the other\n# if not the same."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
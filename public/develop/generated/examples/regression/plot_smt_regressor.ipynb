{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SMT's surrogate model.\n\nThe [surrogate modeling toolbox (SMT)](../../../user_guide/regression/smt.md)\nis an open-source Python package for surrogate modeling,\nwith a focus on derivatives.\nThe [SMTRegressor][gemseo_mlearning.regression.smt_regressor.SMTRegressor] class\nallows you to use any SMT's surrogate model in your GEMSEO processes,\nincluding the gradient-enhanced surrogate models\nas long as your training dataset includes both output and gradient samples\nas explained at the end of [this page](../../../user_guide/regression/smt.md).\n\nIn this example,\nwe will approximate the\n[Rosenbrock function][@molga2005test]\n\n$$f(x,y) = (1-x)^2 + 100(y-x^2)^2$$\n\nover the domain $[-2,2]^2$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom gemseo import compute_doe\nfrom gemseo import sample_disciplines\nfrom gemseo.datasets.io_dataset import IODataset\nfrom gemseo.mlearning.regression.quality.r2_measure import R2Measure\nfrom gemseo.post.dataset.zvsxy import ZvsXY\n\nfrom gemseo_mlearning.problems.rosenbrock.rosenbrock_discipline import (\n    RosenbrockDiscipline,\n)\nfrom gemseo_mlearning.problems.rosenbrock.rosenbrock_space import RosenbrockSpace\nfrom gemseo_mlearning.regression.smt_regressor import SMTRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First,\nwe create the Rosenbrock discipline:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "discipline = RosenbrockDiscipline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the input space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_space = RosenbrockSpace()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe use an optimized Latin hypercube sampling (LHS) technique\nto generate 20 samples:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "training_data = sample_disciplines(\n    [discipline], input_space, \"y\", \"OT_OPT_LHS\", n_samples=20\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this learning dataset,\nwe train an [SMTRegressor][gemseo_mlearning.regression.smt_regressor.SMTRegressor]\nbased on the\n[SMT's RBF surrogate model](https://smt.readthedocs.io/en/latest/_src_docs/surrogate_models/rbf.html)\nwith the basis function scaling parameter `d_0` set to 2.0 (instead of 1.0):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "surrogate_model = SMTRegressor(\n    training_data, model_class_name=\"RBF\", parameters={\"d0\": 2}\n)\nsurrogate_model.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally,\nwe assess its quality:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r2 = R2Measure(surrogate_model)\nr2_l = r2.compute_learning_measure()[0]\nr2_cv = r2.compute_cross_validation_measure()[0]\ntest_data = sample_disciplines(\n    [discipline], input_space, \"y\", \"OT_MONTE_CARLO\", n_samples=1000\n)\nr2_t = r2.compute_test_measure(test_data)[0]\nf\"Learning R2: {r2_l}; cross-validation R2: {r2_cv}; test R2: {r2_t}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "see how good it is with its R2 close to 1 on the test dataset,\nand plot its output over a 20x20 grid:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_data = compute_doe(input_space, algo_name=\"PYDOE_FULLFACT\", n_samples=400)\noutput_data = surrogate_model.predict(input_data)\npredictions = IODataset()\npredictions.add_input_group(input_data, variable_names=[\"x1\", \"x2\"])\npredictions.add_output_group(output_data, variable_names=[\"y\"])\n\nplot = ZvsXY(predictions, \"x1\", \"x2\", \"y\", other_datasets=(training_data,))\nplot.color = \"white\"\nplot.colormap = \"viridis\"\nplot.execute(save=False, show=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
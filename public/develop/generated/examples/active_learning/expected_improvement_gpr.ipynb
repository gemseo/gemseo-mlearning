{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Expected improvement using a Gaussian process regressor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nimport matplotlib.pyplot as plt\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.datasets.io_dataset import IODataset\nfrom gemseo.mlearning.regression.algos.gpr import GaussianProcessRegressor\nfrom numpy import array\nfrom numpy import cos\nfrom numpy import linspace\n\nfrom gemseo_mlearning.active_learning.acquisition_criteria.maximum.ucb import UCB\nfrom gemseo_mlearning.active_learning.acquisition_criteria.minimum.ei import EI\nfrom gemseo_mlearning.active_learning.acquisition_criteria.minimum.lcb import LCB\nfrom gemseo_mlearning.active_learning.active_learning_algo import ActiveLearningAlgo\nfrom gemseo_mlearning.active_learning.distributions.kriging_distribution import (\n    KrigingDistribution,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We consider the function $f(x)=10\\cos(2x)+15-5x+x^2/50$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def f(x):\n    return (10 * cos(2 * x) + 15 - 5 * x + x**2) / 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "defined over the input space $[-3,3]$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_space = DesignSpace()\nlower_bound = -3.0\nupper_bound = 3.0\ninput_space.add_variable(\n    \"x\", lower_bound=lower_bound, upper_bound=upper_bound, value=1.5\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First,\nwe create an initial training dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_train = array([-2.4, -1.2, 0.0, 1.2, 2.4])\ny_train = f(x_train)\n\ntraining_dataset = IODataset()\ntraining_dataset.add_input_variable(\"x\", x_train)\ntraining_dataset.add_output_variable(\"y\", y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and an initial Gaussian process regressor:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gpr = GaussianProcessRegressor(training_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then,\nwe create a Kriging distribution:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kriging_distribution = KrigingDistribution(gpr)\nkriging_distribution.learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "as well as three acquisition criteria:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "expected_improvement = EI(kriging_distribution)\nmean_minus_2sigma = LCB(kriging_distribution, kappa=2.0)\nmean_plus_2sigma = UCB(kriging_distribution, kappa=2.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thirdly,\nwe look for the point that will help us get closer to the minimum;\nby default,\nfor this purpose,\nthe active learning algorithm looks for the point maximizing the expected improvement.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "active_learning = ActiveLearningAlgo(\"Minimum\", input_space, kriging_distribution)\nactive_learning.set_acquisition_algorithm(\"TNC\")\nnext_input_data = active_learning.find_next_point()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fourthly,\nwe evaluate the different acquisition criteria over a fine grid\nas well as the original function and the Gaussian process regressor:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ei_values = []\npredictions = []\nmm2s_values = []\nmp2s_values = []\nx_test = linspace(lower_bound, upper_bound, 200)\ny_test = f(x_test)\nfor x_i in x_test:\n    x_i = array([x_i])\n    predictions.append(gpr.predict(x_i)[0])\n    ei_values.append(expected_improvement.func(x_i)[0])\n    mm2s_values.append(mean_minus_2sigma.func(x_i)[0] * mean_minus_2sigma.output_range)\n    mp2s_values.append(mean_plus_2sigma.func(x_i)[0] * mean_plus_2sigma.output_range)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly,\nwe plot the training points,\nthe original model,\nthe Gaussian process regressor\nand the 95% confidence interval\non a first sub-plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(x_train, y_train, \"ro\", label=\"Training points\")\nax1.plot(x_test, y_test, \"r\", label=\"Original model\")\nax1.plot(x_test, predictions, \"b\", label=\"GP regressor\")\nax1.fill_between(\n    x_test, mm2s_values, mp2s_values, color=\"b\", alpha=0.1, label=\"CI(95%)\"\n)\nax1.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and the expected improvement on a second plots:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax1.legend(loc=\"upper right\")\nax1.axvline(x=next_input_data)\nax2.plot(x_test, ei_values, \"r\", label=\"EI\")\nax2.axvline(x=next_input_data)\nax2.legend()\nax2.grid()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The vertical blue line indicates the point maximizing the expected improvement.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}